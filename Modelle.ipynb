{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMiAti0dGsUBbXZU/pXiYd6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonHauch/bachelorarbeit/blob/main/Modelle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Prfev897WnQB",
        "outputId": "6a190ca6-41bf-4a03-ba92-3e97aa433ec5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1499b3f4-c698-4925-b816-b01ed66246e0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1499b3f4-c698-4925-b816-b01ed66246e0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Bank Customer Churn Prediction.csv to Bank Customer Churn Prediction.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n"
      ],
      "metadata": {
        "id": "68ZgC5fNWwk7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Laden des Datensatzes\n",
        "\n",
        "churn_data = pd.read_csv('Bank Customer Churn Prediction.csv')\n"
      ],
      "metadata": {
        "id": "M8Pw2k-sWwpv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Define features to scale and to encode\n",
        "features_to_scale = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'estimated_salary']\n",
        "features_to_encode = ['country', 'gender']\n",
        "\n",
        "# Set up preprocessing steps using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('scale', StandardScaler(), features_to_scale),\n",
        "        ('encode', OneHotEncoder(drop='first'), features_to_encode)\n",
        "    ])\n",
        "\n",
        "# Extract the 'churn' column before preprocessing\n",
        "y = churn_data['churn']\n",
        "X = churn_data.drop(columns=['churn'])\n",
        "\n",
        "# Apply preprocessing\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Splitting data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'SVM': SVC(random_state=42, probability = True),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Logistic Regression': LogisticRegression(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Train classifiers and evaluate their performance\n",
        "accuracies = {}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    # Train classifier\n",
        "    clf.fit(X_train, y_train)\n",
        "    # Predict on test set\n",
        "    predictions = clf.predict(X_test)\n",
        "    # Evaluate accuracy\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    accuracies[name] = accuracy\n",
        "\n",
        "# Print accuracies for each classifier\n",
        "for name, acc in accuracies.items():\n",
        "    print(f\"{name}: {acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "t8qNZiYVaVwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, recall_score, f1_score\n",
        "# Dictionary to store the metrics\n",
        "metrics = {\n",
        "    'Classifier': [],\n",
        "    'Accuracy': [],\n",
        "    'AUC-ROC': [],\n",
        "    'Recall': [],\n",
        "    'F1 Score': []\n",
        "}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "\n",
        "    # Predict on test set\n",
        "    test_predictions = clf.predict(X_test)\n",
        "    test_probabilities = clf.predict_proba(X_test)[:, 1]  # probabilities for the positive class\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(y_test, test_predictions)\n",
        "    auc_roc = roc_auc_score(y_test, test_probabilities)\n",
        "    recall = recall_score(y_test, test_predictions)\n",
        "    f1 = f1_score(y_test, test_predictions)\n",
        "\n",
        "    # Store metrics\n",
        "    metrics['Classifier'].append(name)\n",
        "    metrics['Accuracy'].append(accuracy)\n",
        "    metrics['AUC-ROC'].append(auc_roc)\n",
        "    metrics['Recall'].append(recall)\n",
        "    metrics['F1 Score'].append(f1)\n",
        "\n",
        "# Convert the metrics dictionary to a pandas DataFrame for a nice table display\n",
        "df_metrics = pd.DataFrame(metrics)\n",
        "\n",
        "# Display the metrics table\n",
        "df_metrics\n"
      ],
      "metadata": {
        "id": "KSIjehjLa7v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparametertuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grids = {\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf']\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [50, 100],\n",
        "        'max_depth': [None, 10, 20]\n",
        "    },\n",
        "    'KNN': {\n",
        "        'n_neighbors': [3, 5, 7]\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'n_estimators': [50, 100],\n",
        "        'learning_rate': [0.01, 0.1]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Dictionary to store best estimators after hyperparameter tuning\n",
        "best_estimators = {}\n",
        "\n",
        "# Perform hyperparameter tuning for each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    if name in param_grids:\n",
        "        grid_search = GridSearchCV(clf, param_grids[name], cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Save the best estimator\n",
        "        best_estimators[name] = grid_search.best_estimator_\n",
        "\n",
        "        # Print results\n",
        "        print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "        print(f\"Best cross-validation score for {name}: {grid_search.best_score_:.2f}\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "# You can then evaluate these optimized models on the test set using the best_estimators dictionary.\n"
      ],
      "metadata": {
        "id": "r0L7xZAUdRMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store the metrics for all classifiers\n",
        "all_metrics = {\n",
        "    'Classifier': [],\n",
        "    'Accuracy': [],\n",
        "    'AUC-ROC': [],\n",
        "    'Recall': [],\n",
        "    'F1 Score': []\n",
        "}\n",
        "\n",
        "# Combine both dictionaries: use tuned classifiers when available, else use the original classifiers\n",
        "combined_classifiers = {name: best_estimators.get(name, clf) for name, clf in classifiers.items()}\n",
        "\n",
        "for name, clf in combined_classifiers.items():\n",
        "\n",
        "    # Predict on test set\n",
        "    test_predictions = clf.predict(X_test)\n",
        "    test_probabilities = clf.predict_proba(X_test)[:, 1]  # probabilities for the positive class\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(y_test, test_predictions)\n",
        "    auc_roc = roc_auc_score(y_test, test_probabilities)\n",
        "    recall = recall_score(y_test, test_predictions)\n",
        "    f1 = f1_score(y_test, test_predictions)\n",
        "\n",
        "    # Store metrics\n",
        "    all_metrics['Classifier'].append(name)\n",
        "    all_metrics['Accuracy'].append(accuracy)\n",
        "    all_metrics['AUC-ROC'].append(auc_roc)\n",
        "    all_metrics['Recall'].append(recall)\n",
        "    all_metrics['F1 Score'].append(f1)\n",
        "\n",
        "# Convert the metrics dictionary to a pandas DataFrame for a nice table display\n",
        "df_all_metrics = pd.DataFrame(all_metrics)\n",
        "\n",
        "# Display the metrics table\n",
        "df_all_metrics\n"
      ],
      "metadata": {
        "id": "75fipEgBeKwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract feature names after preprocessing\n",
        "encoded_features = preprocessor.named_transformers_['encode'].get_feature_names_out(features_to_encode)\n",
        "all_features = np.concatenate([features_to_scale, encoded_features])\n"
      ],
      "metadata": {
        "id": "no0a41UehSHB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime shap"
      ],
      "metadata": {
        "id": "QQdAIw2Fgo5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Sampling\n",
        "\n",
        "# Sample 10 random instances from the test set\n",
        "random_indices = np.random.choice(np.arange(X_test.shape[0]), size=10, replace=False)\n",
        "X_sample = X_test[random_indices]\n",
        "\n",
        "y_sample = y_test.iloc[random_indices].values\n",
        "\n"
      ],
      "metadata": {
        "id": "4Zri4941hlOo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a single instance from the sampled data\n",
        "instance = X_sample[3]\n",
        "true_label = y_sample[3]"
      ],
      "metadata": {
        "id": "_j_lcHtSnp5x"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_test))\n",
        "print(type(X_sample))\n"
      ],
      "metadata": {
        "id": "PUfwh4QaftDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Force Plot (using all features)\n",
        "shap.initjs()  # Initialize JavaScript visualization\n",
        "shap.force_plot(explainer_shap_svm.expected_value[1], shap_value_svm_single, instance, feature_names=all_features)\n"
      ],
      "metadata": {
        "id": "NzP64e0doeDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "explainer_shap_gb = shap.TreeExplainer(classifiers['Gradient Boosting'])\n",
        "shap_values_gb = explainer_shap_gb.shap_values(X_sample)\n"
      ],
      "metadata": {
        "id": "Y2Sj6SNoFmt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the index of the first instance with a negative SHAP value\n",
        "negative_shap_idx = np.where(shap_values_gb < 0)[0][0]\n",
        "negative_instance = X_sample[negative_shap_idx]\n"
      ],
      "metadata": {
        "id": "Hj5sR84tGE2b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer_shap_gb.expected_value, shap_values_gb[1],instance,feature_names = all_features)\n"
      ],
      "metadata": {
        "id": "Y_70fHy3GHYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classifiers)\n"
      ],
      "metadata": {
        "id": "5Dg-X0LoFycR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "# SHAP Initialization for SVM\n",
        "background_data_svm = X_train[np.random.choice(X_train.shape[0], 20, replace=False)]\n",
        "explainer_shap_svm = shap.KernelExplainer(combined_classifiers['SVM'].predict_proba, background_data_svm)\n",
        "\n",
        "# Compute SHAP values for the selected instance using SVM\n",
        "shap_value_svm_single = explainer_shap_svm.shap_values(instance)[1]  # positive class\n",
        "\n",
        "# LIME Initialization for SVM\n",
        "explainer_lime_svm = LimeTabularExplainer(X_train,\n",
        "                                          feature_names=all_features,\n",
        "                                          class_names=['No Churn', 'Churn'],\n",
        "                                          mode='classification')\n",
        "\n",
        "# Compute LIME explanation for the selected instance using SVM\n",
        "exp_svm_single = explainer_lime_svm.explain_instance(instance, combined_classifiers['SVM'].predict_proba, num_features=len(all_features))\n",
        "lime_value_svm_single = [value[1] for value in exp_svm_single.as_list()]\n",
        "\n",
        "# Display the SHAP and LIME values\n",
        "print(\"SHAP values for the selected instance using SVM:\")\n",
        "print(shap_value_svm_single)\n",
        "print(\"\\nLIME values for the selected instance using SVM:\")\n",
        "print(lime_value_svm_single)\n",
        "\n",
        "# Count the number of LIME features with \"Betrag\" >= 0.01\n",
        "lime_features_above_threshold = sum(1 for value in lime_value_svm_single if abs(value) >= 0.01)\n",
        "print(f\"Number of LIME features with Betrag >= 0.01: {lime_features_above_threshold}\")\n"
      ],
      "metadata": {
        "id": "Pq_SXw2jq1Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "import shap\n",
        "# SHAP Initialization for Random Forest using TreeSHAP\n",
        "explainer_shap_rf = shap.TreeExplainer(classifiers['Random Forest'])\n",
        "\n",
        "# Loop through the first 5 instances from X_sample and y_sample\n",
        "for idx in range(5):\n",
        "    instance = X_sample[idx]\n",
        "    true_label = y_sample[idx]\n",
        "\n",
        "    # Compute SHAP values for the selected instance using Random Forest\n",
        "    shap_value_rf_single = explainer_shap_rf.shap_values(instance)[1]  # positive class\n",
        "\n",
        "    # LIME Initialization for Random Forest\n",
        "    explainer_lime_rf = LimeTabularExplainer(X_train,\n",
        "                                             feature_names=all_features,\n",
        "                                             class_names=['No Churn', 'Churn'],\n",
        "                                             mode='classification')\n",
        "\n",
        "    # Compute LIME explanation for the selected instance using Random Forest\n",
        "    exp_rf_single = explainer_lime_rf.explain_instance(instance, classifiers['Random Forest'].predict_proba, num_features=len(all_features))\n",
        "    lime_value_rf_single = [value[1] for value in exp_rf_single.as_list()]\n",
        "\n",
        "    # Display the SHAP and LIME values for the current instance\n",
        "    print(f\"Instance {idx + 1}:\")\n",
        "    print(\"SHAP values:\")\n",
        "    print(shap_value_rf_single)\n",
        "    print(\"\\nLIME values:\")\n",
        "    print(lime_value_rf_single)\n",
        "\n",
        "    # Count the number of LIME features with \"Betrag\" >= 0.01\n",
        "    lime_features_above_threshold_rf = sum(1 for value in lime_value_rf_single if abs(value) >= 0.01)\n",
        "    print(f\"Number of LIME features with Betrag >= 0.01 for Random Forest: {lime_features_above_threshold_rf}\")\n",
        "\n",
        "    # SHAP Force Plot (using all features)\n",
        "    shap.initjs()  # Initialize JavaScript visualization\n",
        "    shap.force_plot(explainer_shap_rf.expected_value[1], shap_value_rf_single, instance, feature_names=all_features)\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "id": "2oqDw6lR1gEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Initialization for Random Forest using TreeSHAP\n",
        "explainer_shap_rf = shap.TreeExplainer(classifiers['Random Forest'])\n",
        "\n",
        "# Select the first instance\n",
        "instance = X_sample[0]\n",
        "\n",
        "# Compute SHAP values for the selected instance using Random Forest\n",
        "shap_value_rf_single = explainer_shap_rf.shap_values(instance)[1]  # positive class\n",
        "\n",
        "# SHAP Force Plot (using all features)\n",
        "shap.initjs()  # Initialize JavaScript visualization\n",
        "shap.force_plot(explainer_shap_rf.expected_value[1], shap_value_rf_single, instance, feature_names=all_features)\n"
      ],
      "metadata": {
        "id": "uHu_HuAb2wZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Initialization for KNN using KernelExplainer\n",
        "background_data_knn = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]  # Using 100 background samples\n",
        "explainer_shap_knn = shap.KernelExplainer(classifiers['KNN'].predict_proba, background_data_knn)\n",
        "\n",
        "# Loop through the first 5 instances from X_sample and y_sample\n",
        "for idx in range(5):\n",
        "    instance = X_sample[idx]\n",
        "    true_label = y_sample[idx]\n",
        "\n",
        "    # Compute SHAP values for the selected instance using KNN\n",
        "    shap_value_knn_single = explainer_shap_knn.shap_values(instance)[1]  # positive class\n",
        "\n",
        "    # LIME Initialization for KNN\n",
        "    explainer_lime_knn = LimeTabularExplainer(X_train,\n",
        "                                              feature_names=all_features,\n",
        "                                              class_names=['No Churn', 'Churn'],\n",
        "                                              mode='classification')\n",
        "\n",
        "    # Compute LIME explanation for the selected instance using KNN\n",
        "    exp_knn_single = explainer_lime_knn.explain_instance(instance, classifiers['KNN'].predict_proba, num_features=len(all_features))\n",
        "    lime_value_knn_single = [value[1] for value in exp_knn_single.as_list()]\n",
        "\n",
        "    # Display the SHAP and LIME values for the current instance\n",
        "    print(f\"Instance {idx + 1}:\")\n",
        "    print(\"SHAP values:\")\n",
        "    print(shap_value_knn_single)\n",
        "    print(\"\\nLIME values:\")\n",
        "    print(lime_value_knn_single)\n",
        "\n",
        "    # Count the number of LIME features with \"Betrag\" >= 0.01\n",
        "    lime_features_above_threshold_knn = sum(1 for value in lime_value_knn_single if abs(value) >= 0.01)\n",
        "    print(f\"Number of LIME features with Betrag >= 0.01 for KNN: {lime_features_above_threshold_knn}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "UhMca2n179lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Initialization for KNN using KernelExplainer\n",
        "explainer_shap_knn = shap.KernelExplainer(classifiers['KNN'].predict_proba, background_data_knn)\n",
        "\n",
        "# Select the fifth instance\n",
        "instance = X_sample[0]\n",
        "\n",
        "# Compute SHAP values for the selected instance using KNN\n",
        "shap_value_knn_single = explainer_shap_knn.shap_values(instance)[1]  # positive class\n",
        "\n",
        "# SHAP Force Plot (using all features)\n",
        "shap.initjs()  # Initialize JavaScript visualization\n",
        "shap.force_plot(explainer_shap_knn.expected_value[1], shap_value_knn_single, instance, feature_names=all_features)\n"
      ],
      "metadata": {
        "id": "WIA8c0ex8R-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LIME Initialization for KNN\n",
        "explainer_lime_knn = LimeTabularExplainer(X_train,\n",
        "                                          feature_names=all_features,\n",
        "                                          class_names=['No Churn', 'Churn'],\n",
        "                                          mode='classification')\n",
        "# Select the fifth instance\n",
        "instance = X_sample[0]\n",
        "# Compute LIME explanation for the selected instance using KNN\n",
        "exp_knn_single = explainer_lime_knn.explain_instance(instance, classifiers['KNN'].predict_proba, num_features=len(all_features))\n",
        "\n",
        "# Display the LIME plot\n",
        "exp_knn_single.show_in_notebook()\n"
      ],
      "metadata": {
        "id": "4CKIZsbwnLvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Initialization for Naive Bayes using KernelExplainer\n",
        "background_data_nb = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]  # Using 100 background samples\n",
        "explainer_shap_nb = shap.KernelExplainer(classifiers['Naive Bayes'].predict_proba, background_data_nb)\n",
        "\n",
        "# Loop through the first 5 instances from X_sample and y_sample\n",
        "for idx in range(5):\n",
        "    instance = X_sample[idx]\n",
        "    true_label = y_sample[idx]\n",
        "\n",
        "    # Compute SHAP values for the selected instance using Naive Bayes\n",
        "    shap_value_nb_single = explainer_shap_nb.shap_values(instance)[1]  # positive class\n",
        "\n",
        "    # LIME Initialization for Naive Bayes\n",
        "    explainer_lime_nb = LimeTabularExplainer(X_train,\n",
        "                                             feature_names=all_features,\n",
        "                                             class_names=['No Churn', 'Churn'],\n",
        "                                             mode='classification')\n",
        "\n",
        "    # Compute LIME explanation for the selected instance using Naive Bayes\n",
        "    exp_nb_single = explainer_lime_nb.explain_instance(instance, classifiers['Naive Bayes'].predict_proba, num_features=len(all_features))\n",
        "    lime_value_nb_single = [value[1] for value in exp_nb_single.as_list()]\n",
        "\n",
        "    # Display the SHAP and LIME values for the current instance\n",
        "    print(f\"Instance {idx + 1}:\")\n",
        "    print(\"SHAP values:\")\n",
        "    print(shap_value_nb_single)\n",
        "    print(\"\\nLIME values:\")\n",
        "    print(lime_value_nb_single)\n",
        "\n",
        "    # Count the number of LIME features with \"Betrag\" >= 0.01\n",
        "    lime_features_above_threshold_nb = sum(1 for value in lime_value_nb_single if abs(value) >= 0.01)\n",
        "    print(f\"Number of LIME features with Betrag >= 0.01 for Naive Bayes: {lime_features_above_threshold_nb}\")\n"
      ],
      "metadata": {
        "id": "-o9SZpy49aJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Initialization for Naive Bayes using KernelExplainer\n",
        "explainer_shap_nb = shap.KernelExplainer(classifiers['Naive Bayes'].predict_proba, background_data_nb)\n",
        "\n",
        "# Select the fifth instance\n",
        "instance = X_sample[0]\n",
        "\n",
        "# Predict the class using Naive Bayes for the selected instance\n",
        "predicted_class_nb = classifiers['Naive Bayes'].predict(instance.reshape(1, -1))\n",
        "predicted_prob_nb = classifiers['Naive Bayes'].predict_proba(instance.reshape(1, -1))\n",
        "\n",
        "print(f\"Predicted probability for class 1 (Churn) using Naive Bayes: {predicted_prob_nb[0][1]:.4f}\")\n",
        "print(f\"Predicted Class (0 for negative, 1 for positive) using Naive Bayes: {predicted_class_nb[0]}\")\n",
        "\n",
        "# Compute SHAP values for the selected instance using Naive Bayes\n",
        "shap_value_nb_single = explainer_shap_nb.shap_values(instance)[1]  # positive class\n",
        "\n",
        "# SHAP Force Plot (using all features)\n",
        "shap.initjs()  # Initialize JavaScript visualization\n",
        "shap.force_plot(explainer_shap_nb.expected_value[1], shap_value_nb_single, instance, feature_names=all_features)\n"
      ],
      "metadata": {
        "id": "uhnP6MMoxRtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Initialization for Gradient Boosting using TreeSHAP\n",
        "explainer_shap_gb = shap.TreeExplainer(classifiers['Gradient Boosting'])\n",
        "\n",
        "# Loop through the first 5 instances from X_sample and y_sample\n",
        "for idx in range(5):\n",
        "    instance = X_sample[idx]\n",
        "    true_label = y_sample[idx]\n",
        "\n",
        "    # Compute SHAP values for the selected instance using Gradient Boosting\n",
        "    shap_value_gb_single = explainer_shap_gb.shap_values(instance)[1]  # positive class\n",
        "\n",
        "    # LIME Initialization for Gradient Boosting\n",
        "    explainer_lime_gb = LimeTabularExplainer(X_train,\n",
        "                                             feature_names=feature_names,\n",
        "                                             class_names=['No Churn', 'Churn'],\n",
        "                                             mode='classification')\n",
        "\n",
        "    # Compute LIME explanation for the selected instance using Gradient Boosting\n",
        "    exp_gb_single = explainer_lime_gb.explain_instance(instance, classifiers['Gradient Boosting'].predict_proba, num_features=len(feature_names))\n",
        "    lime_value_gb_single = [value[1] for value in exp_gb_single.as_list()]\n",
        "\n",
        "    # Display the SHAP and LIME values for the current instance\n",
        "    print(f\"Instance {idx + 1}:\")\n",
        "    print(\"SHAP values:\")\n",
        "    print(shap_value_gb_single)\n",
        "    print(\"\\nLIME values:\")\n",
        "    print(lime_value_gb_single)\n",
        "\n",
        "    # Count the number of LIME features with \"Betrag\" >= 0.01\n",
        "    lime_features_above_threshold_gb = sum(1 for value in lime_value_gb_single if abs(value) >= 0.01)\n",
        "    print(f\"Number of LIME features with Betrag >= 0.01 for Gradient Boosting: {lime_features_above_threshold_gb}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yiqz6PrA-W6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Initialization for Gradient Boosting using TreeSHAP\n",
        "explainer_shap_gb = shap.TreeExplainer(classifiers['Gradient Boosting'])\n",
        "\n",
        "# Select the fifth instance\n",
        "instance = X_sample[0]\n",
        "\n",
        "# Compute SHAP values for the selected instance using Gradient Boosting\n",
        "shap_value_gb_single = explainer_shap_gb.shap_values(instance)  # Only one array for binary classification\n",
        "\n",
        "\n",
        "# Predicted probability using Gradient Boosting for the selected instance\n",
        "predicted_prob_gb = classifiers['Gradient Boosting'].predict_proba(instance.reshape(1, -1))\n",
        "# Get the predicted class using Gradient Boosting for the selected instance\n",
        "predicted_class_gb = classifiers['Gradient Boosting'].predict(instance.reshape(1, -1))\n",
        "\n",
        "# To display it:\n",
        "print(f\"Predicted Probability for Positive Class: {predicted_prob_gb[0][1]:.4f}\")\n",
        "print(f\"Predicted Class (0 for negative, 1 for positive): {predicted_class_gb[0]}\")\n",
        "\n",
        "print(f\"Predicted probability for class 1 (Churn) using Gradient Boosting: {predicted_prob_gb[0][1]:.4f}\")\n",
        "\n",
        "# SHAP Force Plot (using all features)\n",
        "shap.initjs()  # Initialize JavaScript visualization\n",
        "shap.force_plot(explainer_shap_gb.expected_value, shap_value_gb_single, instance, feature_names = all_features)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GyAhehYc-Z_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of instance:\", instance.shape)\n",
        "print(\"Shape of shap_value_gb_single:\", shap_value_gb_single.shape)\n"
      ],
      "metadata": {
        "id": "iYMB3XuM_AVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "classifiers = ['Naive Bayes', 'KNN', 'SVM', 'Random Forest', 'Gradient Boosting']\n",
        "shap_values = [6.6, 8, 7.2, 7.4, 5.8]\n",
        "lime_values = [6.2, 5.2, 6.4, 6.8, 5.2]\n",
        "\n",
        "# Colors\n",
        "lime_color = \"#90ee90\"  # light green\n",
        "shap_colors_tree = \"#ff9999\"  # light red\n",
        "shap_colors_kernel = \"#dda0dd\"  # light violet\n",
        "\n",
        "# Deciding colors based on classifier type\n",
        "shap_colors = [shap_colors_kernel, shap_colors_kernel, shap_colors_kernel, shap_colors_tree, shap_colors_tree]\n",
        "\n",
        "# Bar width\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(classifiers))\n",
        "\n",
        "# Create bars\n",
        "fig, ax = plt.subplots()\n",
        "bar1 = ax.bar(index, shap_values, bar_width, label='Shap', color=shap_colors)\n",
        "bar2 = ax.bar(index + bar_width, lime_values, bar_width, label='Lime', color=lime_color)\n",
        "\n",
        "# Descriptions\n",
        "ax.set_xlabel('Classifier')\n",
        "ax.set_ylabel('Durschnittliche Anzahl dargestellter Features')\n",
        "ax.set_title('Durschnittliche Anzahl dargestellter Features ')\n",
        "ax.set_xticks(index + bar_width / 2)\n",
        "ax.set_xticklabels(classifiers)\n",
        "ax.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kQI3nLjNCnPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "classifiers = ['Naive Bayes', 'KNN', 'SVM', 'Random Forest', 'Gradient Boosting']\n",
        "shap_values = [6.6, 8, 7.2, 7.4, 5.8]\n",
        "lime_values = [6.2, 5.2, 6.4, 6.8, 5.2]\n",
        "\n",
        "# Colors\n",
        "lime_color = \"#90ee90\"  # light green\n",
        "shap_colors_tree = \"#ff9999\"  # light red\n",
        "shap_colors_kernel = \"#dda0dd\"  # light violet\n",
        "\n",
        "# Deciding colors based on classifier type\n",
        "shap_colors = [shap_colors_kernel, shap_colors_kernel, shap_colors_kernel, shap_colors_tree, shap_colors_tree]\n",
        "\n",
        "# Bar width\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(classifiers))\n",
        "\n",
        "# Create bars\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Two SHAP bars for legend differentiation\n",
        "bar_shap_tree = ax.bar(index, shap_values, bar_width, label='SHAP Tree', color=shap_colors_tree)  # Invisible bar just for legend\n",
        "bar_shap_kernel = ax.bar(index, shap_values, bar_width, label='SHAP Kernel', color=shap_colors_kernel)  # Invisible bar just for legend\n",
        "\n",
        "# Actual SHAP and LIME bars\n",
        "bar1 = ax.bar(index, shap_values, bar_width, color=shap_colors)\n",
        "bar2 = ax.bar(index + bar_width, lime_values, bar_width, label='LIME', color=lime_color)\n",
        "\n",
        "# Descriptions\n",
        "ax.set_xlabel('Classifier')\n",
        "ax.set_ylabel('Durschnittliche Anzahl dargestellter Features')\n",
        "ax.set_title('Durschnittliche Anzahl dargestellter Features nach Methode und Modell')\n",
        "ax.set_xticks(index + bar_width / 2)\n",
        "ax.set_xticklabels(classifiers)\n",
        "ax.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dH5hextEDFdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a random instance\n",
        "random_idx = np.random.choice(X_sample.shape[0])\n",
        "instance = X_sample[random_idx]\n",
        "\n"
      ],
      "metadata": {
        "id": "VYcH244HFKu3"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_levels = np.linspace(0, 1, 10)  # Ten noise levels from 0 to 1\n",
        "perturbed_instances = [instance + np.random.normal(0, noise, instance.shape) for noise in noise_levels]\n"
      ],
      "metadata": {
        "id": "eHFr-Th1HY14"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 20 random samples from X_train as the background dataset\n",
        "background_data_svm = X_train[np.random.choice(X_train.shape[0], 20, replace=False)]\n",
        "\n",
        "# Initialize SHAP explainer with the background data\n",
        "explainer_shap_svm = shap.KernelExplainer(classifiers['SVM'].predict_proba, background_data_svm)\n",
        "\n",
        "# Initialize LIME explainer\n",
        "explainer_lime_svm = LimeTabularExplainer(X_train,\n",
        "                                          feature_names=all_features,\n",
        "                                          class_names=['No Churn', 'Churn'],\n",
        "                                          mode='classification')\n",
        "\n",
        "# Compute SHAP and LIME explanations\n",
        "shap_explanations = [explainer_shap_svm.shap_values(inst)[1] for inst in perturbed_instances]\n",
        "lime_explanations = [explainer_lime_svm.explain_instance(inst, classifiers['SVM'].predict_proba, num_features=len(all_features)).as_list() for inst in perturbed_instances]\n"
      ],
      "metadata": {
        "id": "ilL856h8HeQU"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute cosine similarities\n",
        "original_shap = shap_explanations[0]\n",
        "original_lime = np.array([val[1] for val in lime_explanations[0]])\n",
        "\n",
        "shap_similarities = [cosine_similarity([original_shap], [shap_exp])[0][0] for shap_exp in shap_explanations]\n",
        "lime_similarities = [cosine_similarity([original_lime], [np.array([val[1] for val in lime_exp])])[0][0] for lime_exp in lime_explanations]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(noise_levels, shap_similarities, '-o', label='SHAP', color='violet')\n",
        "plt.plot(noise_levels, lime_similarities, '-o', label='LIME', color='green')\n",
        "plt.title('Stability of SHAP and LIME Explanations with Increasing Noise for SVM')\n",
        "plt.xlabel('Noise Level')\n",
        "plt.ylabel('Cosine Similarity with Original Explanation')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GrhxQB8RNREP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "# Initialize SHAP explainer for Logistic Regression\n",
        "background_data_lr = X_train[np.random.choice(X_train.shape[0], 20, replace=False)]\n",
        "explainer_shap_lr = shap.KernelExplainer(classifiers['Logistic Regression'].predict_proba, background_data_lr)\n",
        "\n",
        "# Initialize LIME explainer for Logistic Regression\n",
        "explainer_lime_lr = LimeTabularExplainer(X_train,\n",
        "                                         feature_names=all_features,\n",
        "                                         class_names=['No Churn', 'Churn'],\n",
        "                                         mode='classification')\n",
        "\n",
        "# Compute SHAP and LIME explanations for perturbed instances\n",
        "shap_explanations_lr = [explainer_shap_lr.shap_values(inst)[1] for inst in perturbed_instances]\n",
        "lime_explanations_lr = [explainer_lime_lr.explain_instance(inst, classifiers['Logistic Regression'].predict_proba, num_features=len(all_features)).as_list() for inst in perturbed_instances]\n",
        "\n",
        "# Compute cosine similarities between original and perturbed explanations\n",
        "original_shap_lr = shap_explanations_lr[0]\n",
        "original_lime_lr = np.array([val[1] for val in lime_explanations_lr[0]])\n",
        "\n",
        "shap_similarities_lr = [cosine_similarity([original_shap_lr], [shap_exp])[0][0] for shap_exp in shap_explanations_lr]\n",
        "lime_similarities_lr = [cosine_similarity([original_lime_lr], [np.array([val[1] for val in lime_exp])])[0][0] for lime_exp in lime_explanations_lr]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(noise_levels, shap_similarities_lr, '-o', label='SHAP', color='violet')\n",
        "plt.plot(noise_levels, lime_similarities_lr, '-o', label='LIME', color='green')\n",
        "plt.title('Stability of SHAP and LIME Explanations with Increasing Noise for Logistic Regression')\n",
        "plt.xlabel('Noise Level')\n",
        "plt.ylabel('Cosine Similarity with Original Explanation')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vRzuxOsK59Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 5 random instances\n",
        "random_indices = np.random.choice(X_sample.shape[0], 5, replace=False)\n",
        "instances = X_sample[random_indices]\n"
      ],
      "metadata": {
        "id": "Lc7JWRkrQUq5"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Initialize the background data for SHAP\n",
        "background_data = X_train[np.random.choice(X_train.shape[0], 20, replace=False)]\n",
        "\n",
        "# Storage for computation times\n",
        "times = {'LIME': [], 'SHAP': []}\n",
        "\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "    # Initialize LIME explainer\n",
        "    explainer_lime = LimeTabularExplainer(X_train,\n",
        "                                          feature_names=feature_names,\n",
        "                                          class_names=['No Churn', 'Churn'],\n",
        "                                          mode='classification')\n",
        "\n",
        "    # Compute LIME explanations and record time\n",
        "    start_time = time.time()\n",
        "    for instance in instances:\n",
        "        explainer_lime.explain_instance(instance, classifier.predict_proba, num_features=len(feature_names))\n",
        "    end_time = time.time()\n",
        "    times['LIME'].append(end_time - start_time)\n",
        "\n",
        "    # Check if classifier is tree-based (Random Forest or Gradient Boosting)\n",
        "    if classifier_name in ['Random Forest', 'Gradient Boosting']:\n",
        "        explainer_shap = shap.TreeExplainer(classifier, background_data)\n",
        "    else:\n",
        "        explainer_shap = shap.KernelExplainer(classifier.predict_proba, background_data)\n",
        "\n",
        "    # Compute SHAP explanations and record time\n",
        "    start_time = time.time()\n",
        "    for instance in instances:\n",
        "        explainer_shap.shap_values(instance)\n",
        "    end_time = time.time()\n",
        "    times['SHAP'].append(end_time - start_time)\n"
      ],
      "metadata": {
        "id": "eUULCe0_QcR6"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "labels = list(classifiers.keys())\n",
        "lime_times = times['LIME']\n",
        "shap_times = times['SHAP']\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,7))\n",
        "rects1 = ax.bar(x - width/2, lime_times, width, label='LIME', color='green')\n",
        "rects2 = ax.bar(x + width/2, shap_times, width, label='SHAP', color='violet')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Computation Time (seconds)')\n",
        "ax.set_title('Computation times by explanation method and classifier')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "ax.bar_label(rects1, padding=3)\n",
        "ax.bar_label(rects2, padding=3)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sGMN51LaREZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complexity_levels = [10, 50, 100, 200, 500, 1000]\n"
      ],
      "metadata": {
        "id": "_o-8ORPYSjtm"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize the background data for SHAP\n",
        "background_data = X_train[np.random.choice(X_train.shape[0], 20, replace=False)]\n",
        "\n",
        "# Storage for computation times\n",
        "times = {'LIME': [], 'Tree SHAP': [], 'Kernel SHAP': []}\n",
        "\n",
        "# Initialize LIME explainer\n",
        "explainer_lime = LimeTabularExplainer(X_train,\n",
        "                                      feature_names=feature_names,\n",
        "                                      class_names=['No Churn', 'Churn'],\n",
        "                                      mode='classification')\n",
        "\n",
        "for n_estimators in complexity_levels:\n",
        "    # Train Gradient Boosting classifier\n",
        "    gb = GradientBoostingClassifier(n_estimators=n_estimators, random_state=42)\n",
        "    gb.fit(X_train, y_train)\n",
        "\n",
        "    # Compute LIME explanations and record time\n",
        "    start_time = time.time()\n",
        "    for instance in instances:\n",
        "        explainer_lime.explain_instance(instance, gb.predict_proba, num_features=len(feature_names))\n",
        "    end_time = time.time()\n",
        "    times['LIME'].append(end_time - start_time)\n",
        "\n",
        "    # Initialize Tree SHAP explainer for Gradient Boosting\n",
        "    explainer_tree_shap = shap.TreeExplainer(gb, background_data)\n",
        "\n",
        "    # Compute Tree SHAP explanations and record time\n",
        "    start_time = time.time()\n",
        "    for instance in instances:\n",
        "        explainer_tree_shap.shap_values(instance)\n",
        "    end_time = time.time()\n",
        "    times['Tree SHAP'].append(end_time - start_time)\n",
        "\n",
        "    # Initialize Kernel SHAP explainer for Gradient Boosting\n",
        "    explainer_kernel_shap = shap.KernelExplainer(gb.predict_proba, background_data)\n",
        "\n",
        "    # Compute Kernel SHAP explanations and record time\n",
        "    start_time = time.time()\n",
        "    for instance in instances:\n",
        "        explainer_kernel_shap.shap_values(instance)\n",
        "    end_time = time.time()\n",
        "    times['Kernel SHAP'].append(end_time - start_time)\n"
      ],
      "metadata": {
        "id": "Q3bzqsKzU9rw"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "lime_times = times['LIME']\n",
        "tree_shap_times = times['Tree SHAP']\n",
        "kernel_shap_times = times['Kernel SHAP']\n",
        "\n",
        "plt.figure(figsize=(14,8))\n",
        "plt.plot(complexity_levels, lime_times, '-o', label='LIME', color='green')\n",
        "plt.plot(complexity_levels, tree_shap_times, '-o', label='Tree SHAP', color='violet')\n",
        "plt.plot(complexity_levels, kernel_shap_times, '-o', label='Kernel SHAP', color='blue')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "plt.ylabel('Computation Time (seconds)')\n",
        "plt.title('Computation times by explanation method for varying model complexities')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8gvMbgwvVQD_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}